{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "adb99d41-c151-4dc7-80d9-405ec3d45a18",
    "_uuid": "ef91ec21ad7dbb55a77b760091e35ea8bdbb9a91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime \n",
    "start_real = datetime.now()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dropout, Dense, concatenate, GRU, Embedding, Flatten, Activation\n",
    "# from keras.layers import Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "# set seed\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b84221d8-2ced-43db-90c8-94ef5ee9e707",
    "_uuid": "3b4290b96e65b16b80a7f171b44f546f3b2ea493",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle(Y, Y_pred):\n",
    "    assert Y.shape == Y_pred.shape\n",
    "    return np.sqrt(np.mean(np.square(Y_pred - Y )))\n",
    "\n",
    "def root_mean_squared_logarithmic_error(y_true, y_pred):\n",
    "    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
    "    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
    "    return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1)+0.0000001)\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)+0.0000001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "949a8eb5-a530-46ae-8874-859a785967f8",
    "_uuid": "ed0effa8967da098941de9ea8521de8bb4544da3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 8)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "FLAG_LOAD_TEST = False\n",
    "FLAG_MAKE_SAMPLE = True\n",
    "\n",
    "train_df = pd.read_table('input/train.tsv')\n",
    "if FLAG_MAKE_SAMPLE:\n",
    "    train_df = train_df.sample(10000)\n",
    "print(train_df.shape)\n",
    "\n",
    "if FLAG_LOAD_TEST:\n",
    "    test_df = pd.read_table('input/test.tsv')\n",
    "    print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "c8de06b8-d733-4f85-bd79-839543a2f97f",
    "_uuid": "fb54e437c2a6d9d30a5eb1e25af16c48e40a52a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9995, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove low prices\n",
    "train_df = train_df.drop(train_df[(train_df.price < 3.0)].index)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "01bae3d0-9cb9-4282-9cd8-87228e1488b4",
    "_uuid": "0845d793f16ca4b36b6c86822a9028b2ac696251"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 45 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get name and description lengths\n",
    "def wordCount(text):\n",
    "    try:\n",
    "        if text == 'No description yet':\n",
    "            return 0\n",
    "        else:\n",
    "            text = text.lower()\n",
    "            words = [w for w in text.split(\" \")]\n",
    "            return len(words)\n",
    "    except: \n",
    "        return 0\n",
    "train_df['desc_len'] = train_df['item_description'].apply(lambda x: wordCount(x))\n",
    "train_df['name_len'] = train_df['name'].apply(lambda x: wordCount(x))\n",
    "\n",
    "if FLAG_LOAD_TEST:\n",
    "    test_df['desc_len'] = test_df['item_description'].apply(lambda x: wordCount(x))\n",
    "    test_df['name_len'] = test_df['name'].apply(lambda x: wordCount(x))\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "8933d90c-32b2-4fcb-abf5-58edb50d9870",
    "_uuid": "0c77f5bc7457ee7646f9b50918a14361408adc4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# split category name into 3 parts\n",
    "def split_cat(text):\n",
    "    try: return text.split(\"/\")\n",
    "    except: return (\"No Label\", \"No Label\", \"No Label\")\n",
    "train_df['subcat_0'], train_df['subcat_1'], train_df['subcat_2'] = \\\n",
    "zip(*train_df['category_name'].apply(lambda x: split_cat(x)))\n",
    "\n",
    "if FLAG_LOAD_TEST:\n",
    "    test_df['subcat_0'], test_df['subcat_1'], test_df['subcat_2'] = \\\n",
    "    zip(*test_df['category_name'].apply(lambda x: split_cat(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "1fd00304-f8b1-48fd-acd2-4601a12f3c7b",
    "_uuid": "1fd724dc18f501c1c057e5a28fcf5e5d086f9dad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420\n",
      "Wall time: 226 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "full_set = pd.concat([train_df])\n",
    "if FLAG_LOAD_TEST:\n",
    "    full_set = pd.concat([train_df,test_df])\n",
    "    \n",
    "all_brands = set(full_set['brand_name'].values)\n",
    "train_df.brand_name.fillna(value=\"missing\", inplace=True)\n",
    "\n",
    "if FLAG_LOAD_TEST:\n",
    "    test_df.brand_name.fillna(value=\"missing\", inplace=True)\n",
    "\n",
    "# get to finding!\n",
    "premissing = len(train_df.loc[train_df['brand_name'] == 'missing'])\n",
    "def brandfinder(line):\n",
    "    brand = line[0]\n",
    "    name = line[1]\n",
    "    namesplit = name.split(' ')\n",
    "    if brand == 'missing':\n",
    "        for x in namesplit:\n",
    "            if x in all_brands:\n",
    "                return name\n",
    "    if name in all_brands:\n",
    "        return name\n",
    "    return brand\n",
    "train_df['brand_name'] = train_df[['brand_name','name']].apply(brandfinder, axis = 1)\n",
    "\n",
    "if FLAG_LOAD_TEST:\n",
    "    test_df['brand_name'] = test_df[['brand_name','name']].apply(brandfinder, axis = 1)\n",
    "found = premissing-len(train_df.loc[train_df['brand_name'] == 'missing'])\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ba28847d-aa45-4153-9ae1-fd0aa0f48ac4",
    "_uuid": "2262c6d7cbe571316d4f64bcac6647fe0b98654c"
   },
   "source": [
    "Standard split the train test for validation and log the price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "ed6bc20a-1674-454e-9a88-c7a7fa05dcae",
    "_uuid": "cd3fe6e0c98aa258ac9747b58bfb865451df1016"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 7996 examples\n",
      "Validating on 1999 examples\n"
     ]
    }
   ],
   "source": [
    "# Scale target variable to log.\n",
    "train_df[\"target\"] = np.log1p(train_df.price)\n",
    "\n",
    "# Split training examples into train/dev examples.\n",
    "train_df, dev_df = train_test_split(train_df, test_size=0.2, random_state =102)\n",
    "\n",
    "# Calculate number of train/dev/test examples.\n",
    "n_trains = train_df.shape[0]\n",
    "n_devs = dev_df.shape[0]\n",
    "\n",
    "print(\"Training on\", n_trains, \"examples\")\n",
    "print(\"Validating on\", n_devs, \"examples\")\n",
    "\n",
    "if FLAG_LOAD_TEST:\n",
    "    n_tests = test_df.shape[0]\n",
    "    print(\"Testing on\", n_tests, \"examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3ce824f3-dcbd-453b-92ba-e490e4cd9d84",
    "_uuid": "74cbbf48ca09e2f487ca6f6a7e170c2f58c32291"
   },
   "source": [
    "# Ridge Models\n",
    "\n",
    "Now onto the Ridge models. Less to play with in the Ridge models but it is faster than the RNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "34c19c19-e90e-4a3e-b4a7-eb55ca00848c",
    "_uuid": "d234a8ac2c9aa67c7e173fcab684f4856ed82752",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate train - dev - test data for easy to handle\n",
    "\n",
    "if FLAG_LOAD_TEST:\n",
    "    full_df = pd.concat([train_df, dev_df, test_df])\n",
    "else:\n",
    "    full_df = pd.concat([train_df, dev_df])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "950a555e-fc91-45db-b969-fbe141af9aea",
    "_uuid": "02fe1644a1da61d0e4e6d88f13e03fb60f09d43a"
   },
   "source": [
    "## Handle missing data and convert data type to string\n",
    "All inputs must be strings in a ridge model. The other note here is that filling NAs for item_description use 'No description yet' so it is read the same as the 'No description yet' entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "8835e22b-d064-4bc6-acb4-567c44d4428f",
    "_uuid": "7cc69ef79fecd5dc042599f3ec04d0207668d287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n",
      "Wall time: 89.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Handling missing values...\")\n",
    "full_df['category_name'] = full_df['category_name'].fillna('missing').astype(str)\n",
    "full_df['subcat_0'] = full_df['subcat_0'].astype(str)\n",
    "full_df['subcat_1'] = full_df['subcat_1'].astype(str)\n",
    "full_df['subcat_2'] = full_df['subcat_2'].astype(str)\n",
    "full_df['brand_name'] = full_df['brand_name'].fillna('missing').astype(str)\n",
    "full_df['shipping'] = full_df['shipping'].astype(str)\n",
    "full_df['item_condition_id'] = full_df['item_condition_id'].astype(str)\n",
    "full_df['desc_len'] = full_df['desc_len'].astype(str)\n",
    "full_df['name_len'] = full_df['name_len'].astype(str)\n",
    "full_df['item_description'] = full_df['item_description'].fillna('No description yet').astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "185c6a6d-5d2a-4fd7-a7f2-747c680fab8e",
    "_uuid": "51dabf318564e7521af76ac161d2086d8d0ff599"
   },
   "source": [
    "## Vectorizing all the data\n",
    "Takes around 8-10 minutes depending on the inputs used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "04a35027-7b04-4e7c-a432-d0178fcbecac",
    "_uuid": "575135f0c3eede733bfdf704853204905580207e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing data...\n",
      "(9995, 132730) (7996, 132730) (1999, 132730) (0, 132730)\n",
      "Wall time: 1.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Vectorizing data...\")\n",
    "default_preprocessor = CountVectorizer().build_preprocessor()\n",
    "def build_preprocessor(field):\n",
    "    field_idx = list(full_df.columns).index(field)\n",
    "    return lambda x: default_preprocessor(x[field_idx])\n",
    "\n",
    "vectorizer = FeatureUnion([\n",
    "    ('name', CountVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        max_features=50000,\n",
    "        preprocessor=build_preprocessor('name'))),\n",
    "#     ('category_name', CountVectorizer(\n",
    "#         token_pattern='.+',\n",
    "#         preprocessor=build_preprocessor('category_name'))),\n",
    "    ('subcat_0', CountVectorizer(\n",
    "        token_pattern='.+',\n",
    "        preprocessor=build_preprocessor('subcat_0'))),\n",
    "    ('subcat_1', CountVectorizer(\n",
    "        token_pattern='.+',\n",
    "        preprocessor=build_preprocessor('subcat_1'))),\n",
    "    ('subcat_2', CountVectorizer(\n",
    "        token_pattern='.+',\n",
    "        preprocessor=build_preprocessor('subcat_2'))),\n",
    "    ('brand_name', CountVectorizer(\n",
    "        token_pattern='.+',\n",
    "        preprocessor=build_preprocessor('brand_name'))),\n",
    "    ('shipping', CountVectorizer(\n",
    "        token_pattern='\\d+',\n",
    "        preprocessor=build_preprocessor('shipping'))),\n",
    "    ('item_condition_id', CountVectorizer(\n",
    "        token_pattern='\\d+',\n",
    "        preprocessor=build_preprocessor('item_condition_id'))),\n",
    "    ('desc_len', CountVectorizer(\n",
    "        token_pattern='\\d+',\n",
    "        preprocessor=build_preprocessor('desc_len'))),\n",
    "    ('name_len', CountVectorizer(\n",
    "        token_pattern='\\d+',\n",
    "        preprocessor=build_preprocessor('name_len'))),\n",
    "    ('item_description', TfidfVectorizer(\n",
    "        ngram_range=(1, 3),\n",
    "        max_features=100000,\n",
    "        preprocessor=build_preprocessor('item_description'))),\n",
    "])\n",
    "\n",
    "X = vectorizer.fit_transform(full_df.values)\n",
    "\n",
    "X_train = X[:n_trains]\n",
    "Y_train = train_df.target.values.reshape(-1, 1)\n",
    "\n",
    "X_dev = X[n_trains:n_trains+n_devs]\n",
    "Y_dev = dev_df.target.values.reshape(-1, 1)\n",
    "\n",
    "X_test = X[n_trains+n_devs:]\n",
    "print(X.shape, X_train.shape, X_dev.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0f34eca4-762c-480e-a269-8ed327b9b21f",
    "_uuid": "403ef92d6982787c5f5a46bb5a0710d475046259"
   },
   "source": [
    "## Fitting Ridge model on training data\n",
    "A Ridge model with cross validation does *slighly* better than one without, but even with the minimum of 2 CV, it still takes 4-5 minutes. Any more and it becomes impractical for our narrow time limit. A regular ridge model will only take ~30 seconds. So, for the purposes of having another model to predict on, might as well make both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "ef1a3b85-f68e-4ddd-94e4-4c7765dd0cf5",
    "_uuid": "af45b7a71173895c06eb876b1c9c7e1d0c55b4c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Ridge model on training examples...\n",
      "Wall time: 914 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Fitting Ridge model on training examples...\")\n",
    "ridge_model = Ridge(\n",
    "    solver='auto', fit_intercept=True, alpha=1.0,\n",
    "    max_iter=100, normalize=False, tol=0.05, random_state = 1,\n",
    ")\n",
    "ridge_modelCV = RidgeCV(\n",
    "    fit_intercept=True, alphas=[5.0],\n",
    "    normalize=False, cv = 2, scoring='neg_mean_squared_error',\n",
    ")\n",
    "ridge_model.fit(X_train, Y_train)\n",
    "ridge_modelCV.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1cf25071-13be-43e9-be20-6b1200332fd4",
    "_uuid": "75ca7fe30319238f8a6c5697d5ac5782de9caf93"
   },
   "source": [
    "## Evaluating Ridge model on dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "d56220b1-8fb0-444d-b1f2-80c6d866146c",
    "_uuid": "7722eb4220fe38f6c5676f1f68cf417f741ed014",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSL error on dev set: 0.547373677969\n"
     ]
    }
   ],
   "source": [
    "Y_dev_preds_ridge = ridge_model.predict(X_dev)\n",
    "Y_dev_preds_ridge = Y_dev_preds_ridge.reshape(-1, 1)\n",
    "print(\"RMSL error on dev set:\", rmsle(Y_dev, Y_dev_preds_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "a7da3039-e644-4bb1-8654-c2d82ebde9b1",
    "_uuid": "49e5ec7ac594be05d5f2065b61c02b7b53216a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSL error on dev set: 0.54132434514\n"
     ]
    }
   ],
   "source": [
    "Y_dev_preds_ridgeCV = ridge_modelCV.predict(X_dev)\n",
    "Y_dev_preds_ridgeCV = Y_dev_preds_ridgeCV.reshape(-1, 1)\n",
    "print(\"CV RMSL error on dev set:\", rmsle(Y_dev, Y_dev_preds_ridgeCV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fini\n"
     ]
    }
   ],
   "source": [
    "y_pred = ridge_model.predict(X_test)\n",
    "\n",
    "y_pred[y_pred<1.386]=1.386\n",
    "y_pred = np.expm1(y_pred)\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['test_id'] =test_df.test_id.astype(int)\n",
    "sub['price'] = y_pred\n",
    "sub.to_csv('result.csv', index=False)\n",
    "print (\"fini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2ae17cee-26d3-4a98-ab0a-8b6ee47ffadc",
    "_uuid": "f30b94f118190d2da1e5aefaa6e52ff9aabee8bf"
   },
   "source": [
    "# References\n",
    "\n",
    "This was originally based off of this Kernal: https://www.kaggle.com/nvhbk16k53/associated-model-rnn-ridge\n",
    "\n",
    "With ideas gained from the visualizations here: https://www.kaggle.com/thykhuely/mercari-interactive-eda-topic-modelling\n",
    "\n",
    "You can find description of the competition here https://www.kaggle.com/c/mercari-price-suggestion-challenge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
